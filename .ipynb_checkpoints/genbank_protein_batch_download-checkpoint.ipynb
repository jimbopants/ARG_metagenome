{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WB JG 2/1/16\n",
    "# batch downloads genbank protein descriptions + organism for antibiotic resistance genes\n",
    "\n",
    "# imports\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "from Bio import SeqIO\n",
    "from Bio import Entrez\n",
    "\n",
    "# \n",
    "Entrez.email = 'morganleepetrovich@gmail.com'\n",
    " \n",
    "# paths:\n",
    "accessions_textfile = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function definitions\n",
    "def get_accessions(filepath):\n",
    "    \"\"\" Takes a textfile with gi numbers in the second column and returns a list of GI numbers.\"\"\"\n",
    "    accession_numbers = []\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            pieces = line.split(\"\\t\")\n",
    "            if pieces[1].startswith(\"GI\"):\n",
    "                gi = pieces[1][3:-1]\n",
    "                accession_numbers.append(gi)\n",
    "    \n",
    "    return accession_numbers\n",
    "\n",
    "\n",
    "def batch_prot_download(accession_list, start, stop):\n",
    "    \"\"\"Inputs: Accession list, range of values\n",
    "    1. Retrieve name and organism from Genbank\n",
    "    2. Add each (gi, name, organism) to a temporary dataframe \n",
    "    3. Append new dataframe to existing pickled dataframe, save and close it again\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    print \"Downloading record %i to %i using efetch\" %(start+1, stop)\n",
    "    prot_data = {}\n",
    "    stop = min(len(accession_list), stop) #stop early if end of accession_list is reached.\n",
    "    \n",
    "    for gi in accession_list[start:stop]:\n",
    "        # Save each genbank entry as a dictionary so that it is expandable to multiple regions/CDS\n",
    "        values = {}\n",
    "        cds_count=0 \n",
    "        region_count=0 \n",
    "        \n",
    "        # read from genbank\n",
    "        handle = Entrez.efetch(db='protein', id = gi, rettype='gb', retmode='text')\n",
    "        record = SeqIO.read(handle, 'gb')\n",
    "        \n",
    "        # Get description + organism.\n",
    "        try:\n",
    "            split =  record.description.split(\" [\")\n",
    "            name = split[0]\n",
    "            org = split[1][:-2]\n",
    "            values['gi'] = gi\n",
    "            values['name'] = name\n",
    "            values['org'] = org\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # get any potentially relevant features\n",
    "        for i in record.features:\n",
    "            if i.type == \"Region\":\n",
    "                try:\n",
    "                    values['region_{0}'.format(region_count)] = {\n",
    "                                                    'db_xref' : i.qualifiers['db_xref'], \n",
    "                                                     'region' : i.qualifiers['region_name'],\n",
    "                                                     'note' : i.qualifiers['note']} \n",
    "                    region_count +=1\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "            if i.type == \"CDS\":\n",
    "                try:\n",
    "                    keys = i.qualifiers.keys()\n",
    "                    values[\"CD_{0}\".format(cds_count)] = {}\n",
    "                    for j in keys:\n",
    "                        values[\"CD_{0}\".format(cds_count)][j] = i.qualifiers[j]\n",
    "                    cds_count +=1\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "        prot_data[gi] = values\n",
    "            \n",
    "    return prot_data\n",
    "        \n",
    "\n",
    "def batch_processor(accession_list):\n",
    "    \"\"\" Batch processes genbank database requests so they don't ban us\n",
    "    Creates a pickled object after every 1000 requests in case it breaks before reaching 300,000 requests.\n",
    "    Data is stored in a dictionary with keys = gi numbers and name, regions, CDs, and organism as values.\n",
    "    I will probably need to convert to a dataframe later.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get size of accessions file\n",
    "    total_size = len(accession_list)\n",
    "    batch_size = 100\n",
    "    \n",
    "    # Create pickle\n",
    "    pickle.dump({}, open(\"../Output/pickled.p\", \"wb\"),2)\n",
    "    \n",
    "    # Batch process the genbank data\n",
    "    last_known_good = {}\n",
    "    for i in range(0, total_size, batch_size):\n",
    "        last_known_good = pickle.load( open(\"../pickled.p\", \"rb\"))\n",
    "        next_batch = batch_prot_download(accession_list, i, i+batch_size)\n",
    "        last_known_good.update(next_batch)\n",
    "        \n",
    "        # Save updated version and sleep for 60 sec.\n",
    "        pickle.dump(last_known_good, open(\"./pickled.p\", \"wb\"))\n",
    "        #time.sleep(60) # 60?\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: './pickled.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2ac2f36bd549>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# This needs to return something or save as  pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbatch_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccession_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-cdcf4cacca0f>\u001b[0m in \u001b[0;36mbatch_processor\u001b[0;34m(accession_list)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mlast_known_good\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mlast_known_good\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./pickled.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mnext_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_prot_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccession_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mlast_known_good\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: './pickled.p'"
     ]
    }
   ],
   "source": [
    "# Call functions from above\n",
    "accession_list = get_accessions('/Users/jimbo/Downloads/accessions.txt')\n",
    "\n",
    "# This needs to return something or save as  pickle\n",
    "batch_processor(accession_list[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of genbank features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Feature types and qualifiers dictionary values.\n",
    "source: database id, organism, strain. \n",
    "protein: name - same as the decription \n",
    "\n",
    "Region will have a location and a cross-ref db, a note that could be useful,\n",
    "Want to get db_xref, note, and region_name for every region. \n",
    "Save as values = {region_1:{db_xref: stuff, note: stuff, region_name: stuff}, region_2:{}\n",
    "\n",
    "CDs will refer to coded_by == nucleotide accession, \n",
    "values = {CDS_1:{coded_by, note) db_xref: stuff, note: stuff, region_name: stuff}, region_2:{}\n",
    "\n",
    "Possibly some sections are missing.\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
